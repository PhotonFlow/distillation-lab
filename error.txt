(clean-env) PS C:\Users\a0110610\distillation-lab> python run_custom_benchmark.py
Initializing Base Faster R-CNN...
C:\Users\a0110610\distillation-lab\clean-env\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\a0110610\distillation-lab\clean-env\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Swapping standard RoIHeads with SDGRoIHeads...
RoIHeads Swap Successful.
Loading pretrain weights
[RF-DETR] Loaded filtered state_dict into discovered module.
[RF-DETR] Missing keys: ['transformer.enc_out_class_embed.0.weight', 'transformer.enc_out_class_embed.0.bias', 'transformer.enc_out_class_embed.1.weight', 'transformer.enc_out_class_embed.1.bias', 'transformer.enc_out_class_embed.2.weight', 'transformer.enc_out_class_embed.2.bias', 'transformer.enc_out_class_embed.3.weight', 'transformer.enc_out_class_embed.3.bias', 'transformer.enc_out_class_embed.4.weight', 'transformer.enc_out_class_embed.4.bias', 'transformer.enc_out_class_embed.5.weight', 'transformer.enc_out_class_embed.5.bias', 'transformer.enc_out_class_embed.6.weight', 'transformer.enc_out_class_embed.6.bias', 'transformer.enc_out_class_embed.7.weight', 'transformer.enc_out_class_embed.7.bias', 'transformer.enc_out_class_embed.8.weight', 'transformer.enc_out_class_embed.8.bias', 'transformer.enc_out_class_embed.9.weight', 'transformer.enc_out_class_embed.9.bias', 'transformer.enc_out_class_embed.10.weight', 'transformer.enc_out_class_embed.10.bias', 'transformer.enc_out_class_embed.11.weight', 'transformer.enc_out_class_embed.11.bias', 'transformer.enc_out_class_embed.12.weight', 'transformer.enc_out_class_embed.12.bias', 'class_embed.weight', 'class_embed.bias']
[RF-DETR] Unexpected keys: []
--> Eval: SDG Faster R-CNN (train_benchmark) on subset_1_severity_1/clean
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
--> Eval: RF-DETR (base) (train_custom_models) on subset_1_severity_1/clean
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().
UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\aten\src\ATen\native\TensorShape.cpp:4316.)
Traceback (most recent call last):
  File "C:\Users\a0110610\distillation-lab\run_custom_benchmark.py", line 776, in <module>
    main()
  File "C:\Users\a0110610\distillation-lab\run_custom_benchmark.py", line 745, in main
    metrics = evaluate_rfdetr(
  File "C:\Users\a0110610\distillation-lab\clean-env\lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "C:\Users\a0110610\distillation-lab\run_custom_benchmark.py", line 654, in evaluate_rfdetr
    pred = _normalize_rfdetr_output(output, pred_label_offset=pred_label_offset)
  File "C:\Users\a0110610\distillation-lab\run_custom_benchmark.py", line 615, in _normalize_rfdetr_output
    labels = getattr(output, "labels", None) or getattr(output, "class_id", None) or getattr(
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
(clean-env) PS C:\Users\a0110610\distillation-lab> 
